{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320f47c7",
   "metadata": {},
   "source": [
    "# [DRAFT] A box code for volumetric integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c97e1",
   "metadata": {},
   "source": [
    "The basic method I'm implementing here is from {cite:p}`ethridgeNewFastMultipoleAccelerated2001`.\n",
    "\n",
    "Also:\n",
    "{cite:p}`langstonFreespaceAdaptiveFMMBased2011` extended the method to 3D and {cite:p}`malhotraPVFMMParallelKernel2015b` made it distributed and fast.\n",
    "\n",
    "{cite:p}`gholamiFFTFMMMultigrid2016a` demonstrates that an FMM method based on these ideas can be very competitive with other state of the art volumetric Poisson solver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8c48ec",
   "metadata": {},
   "source": [
    "### Next steps:\n",
    "\n",
    "* Split into nearfield and far-field and run the full box code.\n",
    "* Do some runtime benchmarks with the box code.\n",
    "* Function extension by zero as default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daac907",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3767e8",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from tectosaur2.nb_config import setup\n",
    "\n",
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f98c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "\n",
    "from tectosaur2 import gauss_rule\n",
    "from tectosaur2.laplace2d import single_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd2fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = sp.symbols(\"x, y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0129516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sym_soln = 2 + x + y + x ** 2 + y * sp.cos(6 * x) + x * sp.sin(6 * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a963ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_centers = np.array([[0.1, 0.1], [0, 0], [-0.15, 0.1]])\n",
    "alpha = 250\n",
    "ethridge_sym_soln = 0\n",
    "for i in range(3):\n",
    "    r2_i = (x - gaussian_centers[i, 0]) ** 2 + (y - gaussian_centers[i, 1]) ** 2\n",
    "    ethridge_sym_soln += sp.exp(-alpha * r2_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7665b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethridge_sym_laplacian = sp.diff(sp.diff(ethridge_sym_soln, x), x) + sp.diff(\n",
    "    sp.diff(ethridge_sym_soln, y), y\n",
    ")\n",
    "ethridge_soln_fnc = sp.lambdify((x, y), ethridge_sym_soln, \"numpy\")\n",
    "ethridge_laplacian_fnc = sp.lambdify((x, y), ethridge_sym_laplacian, \"numpy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0d63df",
   "metadata": {},
   "source": [
    "## Singular quadrature, poor convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172ad8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(obs_pt, nq):\n",
    "    q_vol, qw_vol = gauss_rule(nq)\n",
    "\n",
    "    qx_vol, qy_vol = np.meshgrid(q_vol, q_vol)\n",
    "    q2d_vol = np.array([qx_vol.flatten(), qy_vol.flatten()]).T.copy()\n",
    "    q2d_vol_wts = (qw_vol[:, None] * qw_vol[None, :]).flatten()\n",
    "    fxy = -ethridge_laplacian_fnc(q2d_vol[:, 0], q2d_vol[:, 1])\n",
    "\n",
    "    u_particular = (\n",
    "        (single_layer.kernel(obs_pt, q2d_vol)[:,0,:,0] * q2d_vol_wts[None, :])\n",
    "        .dot(fxy)\n",
    "        .reshape(obs_pt.shape[0])\n",
    "    )\n",
    "    return u_particular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dcfd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_pt = np.array([[-0.1, -0.1]])\n",
    "correct = ethridge_soln_fnc(obs_pt[0, 0], obs_pt[0, 1])\n",
    "\n",
    "steps = np.arange(2, 1200, 10)\n",
    "ests = np.array([run(obs_pt, s) for s in steps])\n",
    "\n",
    "difference = np.linalg.norm(ests - correct, axis=1) / np.linalg.norm(correct)\n",
    "\n",
    "plt.plot(steps, np.log10(difference))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c946be",
   "metadata": {},
   "source": [
    "## Two-dimensional interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import quadpy\n",
    "\n",
    "def clencurt(n1):\n",
    "    \"\"\"Computes the Clenshaw Curtis quadrature nodes and weights\"\"\"\n",
    "    C = quadpy.c1.clenshaw_curtis(n1)\n",
    "    return (C.points, C.weights)\n",
    "\n",
    "\n",
    "# TODO: is there a quadpy function that does tensor products?\n",
    "def tensor_product(x, w):\n",
    "    rect_x, rect_y = np.meshgrid(x, x)\n",
    "    rect_pts = np.array([rect_x.flatten(), rect_y.flatten()]).T\n",
    "    rect_w = np.outer(w, w).flatten()\n",
    "    return rect_pts, rect_w\n",
    "\n",
    "\n",
    "def clencurt_2d(n):\n",
    "    return tensor_product(*clencurt(n))\n",
    "\n",
    "\n",
    "def cheblob(n):\n",
    "    \"\"\"Computes the chebyshev lobatto.\"\"\"\n",
    "    pts = clencurt(n)[0]\n",
    "    wts = (-1) ** np.arange(n).astype(np.float64)\n",
    "    wts[0] *= 0.5\n",
    "    wts[-1] *= 0.5\n",
    "    return pts, wts  # tensor_product(pts, wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091657fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.finfo(float).eps\n",
    "\n",
    "\n",
    "def barycentric_tensor_product(evalx, evaly, interp_pts, interp_wts, fnc_vals):\n",
    "    \"\"\"\n",
    "    eval_pts is (N, 2)\n",
    "    interp_pts is (Q,)\n",
    "    interp_wts is (Q,)\n",
    "    fnc_vals is (P, Q^2)\n",
    "    \"\"\"\n",
    "\n",
    "    dx = evalx[:, None] - interp_pts\n",
    "    dy = evaly[:, None] - interp_pts\n",
    "\n",
    "    idx0, idx1 = np.where(dx == 0)\n",
    "    dx[idx0, idx1] = eps\n",
    "    idx0, idx1 = np.where(dy == 0)\n",
    "    dy[idx0, idx1] = eps\n",
    "\n",
    "    kernelX = interp_wts[None, :] / dx\n",
    "    kernelY = interp_wts[None, :] / dy\n",
    "    kernel = (kernelX[:, None, :] * kernelY[:, :, None]).reshape(\n",
    "        (-1, fnc_vals.shape[1])\n",
    "    )\n",
    "    return (\n",
    "        np.sum(kernel[None, :] * fnc_vals[:, None, :], axis=2)\n",
    "        / np.sum(kernel, axis=1)[None, :]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945091a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 100\n",
    "zoomx = np.array([-1, 1])\n",
    "zoomy = np.array([-1, 1])\n",
    "xs = np.linspace(*zoomx, nobs)\n",
    "ys = np.linspace(*zoomy, nobs)\n",
    "obsx, obsy = np.meshgrid(xs, ys)\n",
    "obsx_flat = obsx.flatten()\n",
    "obsy_flat = obsy.flatten()\n",
    "obs2d = np.array([obsx_flat, obsy_flat]).T.copy()\n",
    "\n",
    "nI = 90\n",
    "Ix, Iwts = cheblob(nI)\n",
    "Ipts, Iwts2d = tensor_product(Ix, Iwts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9962d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = ethridge_laplacian_fnc(Ipts[:, 0], Ipts[:, 1])\n",
    "F_interp = barycentric_tensor_product(obsx_flat, obsy_flat, Ix, Iwts, np.array([F]))\n",
    "F_interp2d = F_interp.reshape(obsx.shape)\n",
    "F_correct = ethridge_laplacian_fnc(obsx_flat, obsy_flat).reshape(obsx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c4cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8.5,8.5))\n",
    "plt.subplot(2,2,1)\n",
    "levels = np.linspace(np.min(F_correct), np.max(F_correct), 7)\n",
    "cntf = plt.contourf(\n",
    "    Ipts[:, 0].reshape((nI, nI)),\n",
    "    Ipts[:, 1].reshape((nI, nI)),\n",
    "    F.reshape((nI, nI)),\n",
    "    levels=levels,\n",
    "    extend=\"both\",\n",
    ")\n",
    "plt.contour(\n",
    "    Ipts[:, 0].reshape((nI, nI)),\n",
    "    Ipts[:, 1].reshape((nI, nI)),\n",
    "    F.reshape((nI, nI)),\n",
    "    colors=\"k\",\n",
    "    linestyles=\"-\",\n",
    "    linewidths=0.5,\n",
    "    levels=levels,\n",
    "    extend=\"both\",\n",
    ")\n",
    "plt.plot(Ipts[:,0], Ipts[:,1], 'ro', markersize=0.5)\n",
    "plt.colorbar(cntf)\n",
    "plt.xlim(zoomx)\n",
    "plt.ylim(zoomy)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "levels = np.linspace(np.min(F_correct), np.max(F_correct), 7)\n",
    "cntf = plt.contourf(obsx, obsy, F_interp2d, levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    obsx,\n",
    "    obsy,\n",
    "    F_interp2d,\n",
    "    colors=\"k\",\n",
    "    linestyles=\"-\",\n",
    "    linewidths=0.5,\n",
    "    levels=levels,\n",
    "    extend=\"both\",\n",
    ")\n",
    "plt.colorbar(cntf)\n",
    "plt.xlim(zoomx)\n",
    "plt.ylim(zoomy)\n",
    "\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "levels = np.linspace(np.min(F_correct), np.max(F_correct), 7)\n",
    "cntf = plt.contourf(obsx, obsy, F_correct, levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    obsx,\n",
    "    obsy,\n",
    "    F_correct,\n",
    "    colors=\"k\",\n",
    "    linestyles=\"-\",\n",
    "    linewidths=0.5,\n",
    "    levels=levels,\n",
    "    extend=\"both\",\n",
    ")\n",
    "plt.colorbar(cntf)\n",
    "plt.xlim(zoomx)\n",
    "plt.ylim(zoomy)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "levels = np.linspace(-5, 1, 7)\n",
    "err = np.log10(np.abs(F_correct - F_interp2d)) / np.log10(np.mean(np.abs(F_interp2d)))\n",
    "cntf = plt.contourf(obsx, obsy, err, levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    obsx,\n",
    "    obsy,\n",
    "    err,\n",
    "    colors=\"k\",\n",
    "    linestyles=\"-\",\n",
    "    linewidths=0.5,\n",
    "    levels=levels,\n",
    "    extend=\"both\",\n",
    ")\n",
    "plt.colorbar(cntf)\n",
    "plt.xlim(zoomx)\n",
    "plt.ylim(zoomy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44454c8f",
   "metadata": {},
   "source": [
    "## A box code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0629f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = clencurt_2d(4)\n",
    "q2 = clencurt_2d(7)\n",
    "interp1 = cheblob(4)\n",
    "interp2 = cheblob(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0fa3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass()\n",
    "class TreeLevel:\n",
    "    fhigh: np.ndarray\n",
    "    centers: np.ndarray\n",
    "    sizes: np.ndarray\n",
    "    parents: np.ndarray\n",
    "    is_leaf: np.ndarray\n",
    "\n",
    "@dataclass()\n",
    "class Tree:\n",
    "    levels: List[TreeLevel]\n",
    "    leaves: TreeLevel\n",
    "\n",
    "def build_box_tree(f, start_centers, start_sizes, max_levels, tol):\n",
    "    parents = np.zeros(start_centers.shape[0])\n",
    "    centers = start_centers\n",
    "    sizes = start_sizes\n",
    "    levels = []\n",
    "    for i in range(max_levels):\n",
    "        box_low_pts = q1[0][None, :] * 0.5 * sizes[:, None, None] + centers[:, None, :]\n",
    "        box_high_pts = q2[0][None, :] * 0.5 * sizes[:, None, None] + centers[:, None, :]\n",
    "        box_quad_wts = q2[1][None, :] * 0.25 * sizes[:, None] ** 2\n",
    "\n",
    "        f_high = f(\n",
    "            box_high_pts[:, :, 0].ravel(), box_high_pts[:, :, 1].ravel()\n",
    "        ).reshape((box_low_pts.shape[0], interp2[0].shape[0], interp2[0].shape[0]))\n",
    "\n",
    "        # Because the Chebyshev Lobatto/Clenshaw Curtis points are nested, a 2N - 1 point\n",
    "        # rule contains an N point rule inside it.\n",
    "        f_low = f_high[:, ::2, ::2]\n",
    "\n",
    "        f_high_flat = f_high.reshape((centers.shape[0], -1))\n",
    "        f_low_flat = f_low.reshape((centers.shape[0], -1))\n",
    "\n",
    "        # Interpolate to get an error estimate. Note that this error estimate will be\n",
    "        # very conservative because it's estimating the error in the N low accuracy points\n",
    "        # but we will end up using the 2N - 1 high accuracy points.\n",
    "        f_high_interp = barycentric_tensor_product(\n",
    "            q2[0][:, 0], q2[0][:, 1], interp1[0], interp1[1], f_low_flat\n",
    "        )\n",
    "        err = np.sqrt(np.sum((f_high_interp - f_high_flat) ** 2 * box_quad_wts, axis=1))\n",
    "\n",
    "        # Don't refine if we're at the last level.\n",
    "        if i == max_levels - 1:\n",
    "            refine_boxes = np.array([], dtype=np.int64)\n",
    "        else:\n",
    "            refine_boxes = np.where(err > tol)[0]\n",
    "\n",
    "        is_leaf = np.ones(centers.shape[0], dtype=bool)\n",
    "        is_leaf[refine_boxes] = False\n",
    "\n",
    "        levels.append(TreeLevel(f_high_flat, centers, sizes, parents, is_leaf))\n",
    "        if refine_boxes.shape[0] == 0:\n",
    "            break\n",
    "\n",
    "        refine_centers = centers[refine_boxes]\n",
    "        bump = sizes[refine_boxes] / 4\n",
    "\n",
    "        parents = np.repeat(np.arange(centers.shape[0])[refine_boxes], 4)\n",
    "        centers = np.concatenate(\n",
    "            [\n",
    "                refine_centers + np.array([bump, bump]).T,\n",
    "                refine_centers + np.array([-bump, bump]).T,\n",
    "                refine_centers + np.array([bump, -bump]).T,\n",
    "                refine_centers + np.array([-bump, -bump]).T,\n",
    "            ]\n",
    "        )\n",
    "        sizes = np.repeat(sizes[refine_boxes] / 2, 4, axis=0)\n",
    "\n",
    "    return calculate_leaves(Tree(levels=levels, leaves=None))\n",
    "\n",
    "def calculate_leaves(tree):\n",
    "    leaves = []\n",
    "    for i in range(len(tree.levels)):\n",
    "        L = tree.levels[i]\n",
    "        leaves.append((L.fhigh[L.is_leaf], L.centers[L.is_leaf], L.sizes[L.is_leaf], L.parents[L.is_leaf]))\n",
    "\n",
    "    leaf_data = [\n",
    "        np.concatenate([L[i] for L in leaves])\n",
    "        for i in range(4)\n",
    "    ]\n",
    "    leaves = TreeLevel(*leaf_data, np.ones(leaf_data[0].shape[0], dtype=bool))\n",
    "    return Tree(levels = tree.levels, leaves=leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ethridge_tree = build_box_tree(ethridge_laplacian_fnc, np.array([[0, 0]]), np.array([1]), 10, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680720fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethridge_tree.leaves.centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbcda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_level(L):\n",
    "    for i in range(L.centers.shape[0]):\n",
    "        c = L.centers[i]\n",
    "        s = L.sizes[i]\n",
    "        plt.gca().add_patch(\n",
    "            patches.Rectangle(\n",
    "                (c[0] - s / 2, c[1] - s / 2),\n",
    "                s,\n",
    "                s,\n",
    "                edgecolor=\"k\",\n",
    "                facecolor=\"none\",\n",
    "            )\n",
    "        )\n",
    "plot_level(ethridge_tree.leaves)\n",
    "plt.xlim([-0.55, 0.55])\n",
    "plt.ylim([-0.55, 0.55])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2adb5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_quad_wts = (\n",
    "    q2[1][None, :] * 0.25 * ethridge_tree.leaves.sizes[:, None] ** 2\n",
    ")\n",
    "np.sum(box_quad_wts.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e62893",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree = build_box_tree(lambda x, y: np.cos(10 * (x + y)), np.array([[0, 0]]), np.array([1]), 15, 0.000001)\n",
    "\n",
    "box_quad_wts = (\n",
    "    q2[1][None, :] * 0.25 * test_tree.leaves.sizes[:, None] ** 2\n",
    ")\n",
    "\n",
    "correct = 0.0367814305815291\n",
    "est = np.sum(test_tree.leaves.fhigh.ravel() * box_quad_wts.ravel())\n",
    "est, est - correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b044172",
   "metadata": {},
   "source": [
    "## Volumetric Green's function integrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f43fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_eval(tree, obs_pts):\n",
    "    box_high_pts = (\n",
    "        q2[0][None, :] * 0.5 * tree.leaves.sizes[:, None, None] + tree.leaves.centers[:, None, :]\n",
    "    )\n",
    "    box_quad_wts = (\n",
    "        q2[1][None, :] * 0.25 * tree.leaves.sizes[:, None] ** 2\n",
    "    )\n",
    "\n",
    "    G = fundamental_soln_matrix(obs_pts, box_high_pts.reshape((-1, 2)))[:, 0, :]\n",
    "    out = (G * box_quad_wts.ravel()[None,:]).dot(tree.leaves.fhigh.ravel())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b345571",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "obs_test = (np.random.rand(1000, 2) - 0.5) * 0.2\n",
    "est_rand = naive_eval(ethridge_tree, obs_test)\n",
    "soln_rand = ethridge_soln_fnc(obs_test[:,0], obs_test[:,1])\n",
    "err = np.max(np.abs(est_rand - soln_rand)) / np.max(np.abs(soln_rand))\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_soln = naive_eval(ethridge_tree, obs2d).reshape(obsx.shape)\n",
    "soln = ethridge_soln_fnc(obsx_flat, obsy_flat).reshape(obsx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a401ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1,2,1)\n",
    "levels = np.linspace(np.min(soln), np.max(soln), 7)\n",
    "cntf = plt.contourf(obsx, obsy, est_soln, levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    obsx,\n",
    "    obsy,\n",
    "    est_soln,\n",
    "    colors=\"k\",\n",
    "    linestyles=\"-\",\n",
    "    linewidths=0.5,\n",
    "    levels=levels,\n",
    "    extend=\"both\",\n",
    ")\n",
    "plt.colorbar(cntf)\n",
    "plt.xlim(zoomx)\n",
    "plt.ylim(zoomy)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "levels = np.linspace(np.min(soln), np.max(soln), 7)\n",
    "cntf = plt.contourf(obsx, obsy, soln, levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    obsx,\n",
    "    obsy,\n",
    "    soln,\n",
    "    colors=\"k\",\n",
    "    linestyles=\"-\",\n",
    "    linewidths=0.5,\n",
    "    levels=levels,\n",
    "    extend=\"both\",\n",
    ")\n",
    "plt.colorbar(cntf)\n",
    "plt.xlim(zoomx)\n",
    "plt.ylim(zoomy)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "levels = np.linspace(-7, -2, 6)\n",
    "err = np.log10(np.abs(est_soln - soln))\n",
    "cntf = plt.contourf(obsx, obsy, err, levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    obsx,\n",
    "    obsy,\n",
    "    err,\n",
    "    colors=\"k\",\n",
    "    linestyles=\"-\",\n",
    "    linewidths=0.5,\n",
    "    levels=levels,\n",
    "    extend=\"both\",\n",
    ")\n",
    "plt.colorbar(cntf)\n",
    "plt.xlim(zoomx)\n",
    "plt.ylim(zoomy)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee3519e",
   "metadata": {},
   "source": [
    "## The 2:1 balance condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be2f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_f(x, y):\n",
    "    return (y > 0.15) * 1.0\n",
    "discontinuity_tree = build_box_tree(test_f, np.array([[0, 0]]), np.array([1]), 6, 0.001)\n",
    "plot_level(discontinuity_tree.leaves)\n",
    "plt.xlim([-0.55, 0.55])\n",
    "plt.ylim([-0.55, 0.55])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb4e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_21(tree, f, plot_progress=False):\n",
    "    i = 0\n",
    "    while i <= len(tree.levels) - 3:\n",
    "        # We can skip splitting the level above because those cells all satisfy the\n",
    "        # 2:1 criteria already\n",
    "        did_refine = False\n",
    "        for j in range(i + 2, len(tree.levels)):\n",
    "            big_L = tree.levels[i]\n",
    "            small_L = tree.levels[j]\n",
    "            dx = small_L.centers[:,None,0] - big_L.centers[None,:,0]\n",
    "            dy = small_L.centers[:,None,1] - big_L.centers[None,:,1]\n",
    "\n",
    "            closex = np.abs(dx) <= 0.5 * (small_L.sizes[:,None] + big_L.sizes[None,:])\n",
    "            closey = np.abs(dy) <= 0.5 * (small_L.sizes[:,None] + big_L.sizes[None,:])\n",
    "\n",
    "            refine_boxes = np.any(closex & closey, axis=0) & big_L.is_leaf\n",
    "            refine_centers = big_L.centers[refine_boxes]\n",
    "            if refine_centers.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            bump = big_L.sizes[refine_boxes] / 4\n",
    "\n",
    "            parents = np.repeat(np.arange(big_L.centers.shape[0])[refine_boxes], 4)\n",
    "            centers = np.concatenate(\n",
    "                [\n",
    "                    refine_centers + np.array([bump, bump]).T,\n",
    "                    refine_centers + np.array([-bump, bump]).T,\n",
    "                    refine_centers + np.array([bump, -bump]).T,\n",
    "                    refine_centers + np.array([-bump, -bump]).T,\n",
    "                ]\n",
    "            )\n",
    "            sizes = np.repeat(big_L.sizes[refine_boxes] / 2, 4, axis=0)\n",
    "\n",
    "            box_high_pts = q2[0][None, :] * 0.5 * sizes[:, None, None] + centers[:, None, :]\n",
    "            box_quad_wts = q2[1][None, :] * 0.25 * sizes[:, None] ** 2\n",
    "\n",
    "            # TODO: either interpolate here or re-use the original function.\n",
    "            f_high = f(\n",
    "                box_high_pts[:, :, 0].ravel(), box_high_pts[:, :, 1].ravel()\n",
    "            ).reshape((centers.shape[0], -1))\n",
    "            # TODO: at the end, re-calculate leaves.\n",
    "\n",
    "            child_L = tree.levels[i+1]\n",
    "            big_L.is_leaf[refine_boxes] = False\n",
    "            tree.levels[i+1] = TreeLevel(\n",
    "                np.concatenate([child_L.fhigh, f_high]),\n",
    "                np.concatenate([child_L.centers, centers]),\n",
    "                np.concatenate([child_L.sizes, sizes]),\n",
    "                np.concatenate([child_L.parents, parents]),\n",
    "                np.concatenate([child_L.is_leaf, np.ones(centers.shape[0], dtype=bool)])\n",
    "            )\n",
    "            did_refine = True\n",
    "            break\n",
    "\n",
    "        if did_refine:\n",
    "            if plot_progress:\n",
    "                print(f'Splitting {refine_centers.shape[0]} boxes in level {i}')\n",
    "                tree = calculate_leaves(tree)\n",
    "                plot_level(tree.leaves)\n",
    "                plt.xlim([-0.55, 0.55])\n",
    "                plt.ylim([-0.55, 0.55])\n",
    "                plt.axis('equal')\n",
    "                plt.show()\n",
    "            # If cells were refined in this level, then there may be cells in\n",
    "            # the parent's level that now need to be refined, so we back up a step to\n",
    "            # check.\n",
    "            i -= 1\n",
    "        else:\n",
    "            # If no cells were refined, then proceed down the tree to the next level\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdae51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_21(discontinuity_tree, test_f, plot_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7fbcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "discontinuity_tree = calculate_leaves(discontinuity_tree)\n",
    "\n",
    "plot_level(discontinuity_tree.leaves)\n",
    "plt.xlim([-0.55, 0.55])\n",
    "plt.ylim([-0.55, 0.55])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "balanced_tree = copy.deepcopy(ethridge_tree)\n",
    "balance_21(balanced_tree, ethridge_laplacian_fnc)\n",
    "balanced_tree = calculate_leaves(balanced_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_level(ethridge_tree.leaves)\n",
    "plt.xlim([-0.55, 0.55])\n",
    "plt.ylim([-0.55, 0.55])\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_level(balanced_tree.leaves)\n",
    "for i in range(balanced_tree.leaves.centers.shape[0]):\n",
    "    c = balanced_tree.leaves.centers[i]\n",
    "    s = balanced_tree.leaves.sizes[i]\n",
    "    if np.any(np.linalg.norm(c[None,:] - ethridge_tree.leaves.centers, axis=1) == 0):\n",
    "        continue\n",
    "    plt.gca().add_patch(\n",
    "        patches.Rectangle(\n",
    "            (c[0] - s / 2, c[1] - s / 2),\n",
    "            s,\n",
    "            s,\n",
    "            linewidth=2,\n",
    "            edgecolor=\"r\",\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "    )\n",
    "plt.xlim([-0.55, 0.55])\n",
    "plt.ylim([-0.55, 0.55])\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8429314",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "obs_test = (np.random.rand(1000, 2) - 0.5) * 0.2\n",
    "est_rand = naive_eval(balanced_tree, obs_test)\n",
    "soln_rand = ethridge_soln_fnc(obs_test[:,0], obs_test[:,1])\n",
    "err = np.max(np.abs(est_rand - soln_rand)) / np.max(np.abs(soln_rand))\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e5dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_soln_balanced = naive_eval(balanced_tree, obs2d).reshape(obsx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2936682",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(est_soln - est_soln_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd004b",
   "metadata": {},
   "source": [
    "## Using precomputed near-field integrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40eae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = {\n",
    "    # Type 0 (coincident)\n",
    "    (1, 0, 0): (0, 1, 1, 0),\n",
    "    # Type 1\n",
    "    (1, 2, 2): (1, 1, 1, 0),\n",
    "    (1, -2, 2): (1, -1, 1, 0),\n",
    "    (1, -2, -2): (1, -1, -1, 0),\n",
    "    (1, 2, -2): (1, 1, -1, 0),\n",
    "    # Type 2\n",
    "    (1, 2, 0): (2, 1, 1, 0),\n",
    "    (1, 0, 2): (2, 1, 1, 1),\n",
    "    (1, -2, 0): (2, -1, 1, 0),\n",
    "    (1, 0, -2): (2, 1, -1, 1),\n",
    "    # Type 3\n",
    "    (2, 3, 3): (3, 1, 1, 0),\n",
    "    (2, -3, 3): (3, -1, 1, 0),\n",
    "    (2, -3, -3): (3, -1, -1, 0),\n",
    "    (2, 3, -3): (3, 1, -1, 0),\n",
    "    # Type 4\n",
    "    (2, 1, 3): (4, 1, 1, 1),\n",
    "    (2, -1, 3): (4, -1, 1, 1),\n",
    "    (2, -3, 1): (4, -1, 1, 0),\n",
    "    (2, -3, -1): (4, -1, -1, 0),\n",
    "    (2, -1, -3): (4, -1, -1, 1),\n",
    "    (2, 1, -3): (4, 1, -1, 1),\n",
    "    (2, 3, -1): (4, 1, -1, 0),\n",
    "    (2, 3, 1): (4, 1, 1, 0),\n",
    "    # Type 5\n",
    "    (0.5, 1.5, 1.5): (5, 1, 1, 0),\n",
    "    (0.5, -1.5, 1.5): (5, -1, 1, 0),\n",
    "    (0.5, -1.5, -1.5): (5, -1, -1, 0),\n",
    "    (0.5, 1.5, -1.5): (5, 1, -1, 0),\n",
    "    # Type 6\n",
    "    (0.5, 0.5, 1.5): (6, 1, 1, 1),\n",
    "    (0.5, -0.5, 1.5): (6, -1, 1, 1),\n",
    "    (0.5, -1.5, 0.5): (6, -1, 1, 0),\n",
    "    (0.5, -1.5, -0.5): (6, -1, -1, 0),\n",
    "    (0.5, -0.5, -1.5): (6, -1, -1, 1),\n",
    "    (0.5, 0.5, -1.5): (6, 1, -1, 1),\n",
    "    (0.5, 1.5, -0.5): (6, 1, -1, 0),\n",
    "    (0.5, 1.5, 0.5): (6, 1, 1, 0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c28da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearfield_box(I, Fv, flipx, flipy, rotxy):\n",
    "    # NOTE: The transpose is necessary simply because the definition of the basis functions here is the transpose of the definition in precompute. I should fix this!\n",
    "    N = int(np.sqrt(Fv.shape[0]))\n",
    "    Fv = Fv.reshape((N,N)).T\n",
    "\n",
    "    n_rot = {\n",
    "        (1, 1): 0,\n",
    "        (1, -1): 1,\n",
    "        (-1, -1): 2,\n",
    "        (-1, 1): 3\n",
    "    }[(flipx, flipy)]\n",
    "    n_transpose = ((n_rot % 2) == 1) + rotxy\n",
    "\n",
    "    # Rotate from input coordinates into position\n",
    "    Fv = np.rot90(Fv, n_rot)\n",
    "    if n_transpose % 2 == 1:\n",
    "        Fv = Fv.T\n",
    "\n",
    "    est = I.dot(Fv.ravel())\n",
    "\n",
    "    # Reverse the transformation back to the original input space\n",
    "    if n_transpose % 2 == 1:\n",
    "        est = est.T\n",
    "    est = np.rot90(est, -n_rot)\n",
    "    return est\n",
    "\n",
    "def scale_integral(I, basis_dot_F, src_s):\n",
    "    scale_T = src_s / 2.0\n",
    "    C = scale_T ** 2\n",
    "    log_factor = C * (1 / (2 * np.pi)) * np.log(scale_T)\n",
    "    return C * I + log_factor * basis_dot_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ff3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_integrals, nearfield_integrals = np.load(\"data/nearfield_integrals.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ac0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearfield_integrals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_tree = build_box_tree(ethridge_laplacian_fnc, np.array([[0, 0]]), np.array([1]), 50, 10.0)\n",
    "print(f'built tree with {new_tree.leaves.centers.shape[0] * q2[0].shape[0]} degrees of freedom, {new_tree.leaves.centers.shape[0]} leaves, and {len(new_tree.levels)} levels')\n",
    "\n",
    "balance_21(new_tree, ethridge_laplacian_fnc)\n",
    "new_tree = calculate_leaves(new_tree)\n",
    "print(f'balanced tree has {new_tree.leaves.centers.shape[0]} leaves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c48af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_level(new_tree.leaves)\n",
    "plt.xlim([-0.55, 0.55])\n",
    "plt.ylim([-0.55, 0.55])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00028802",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "box_high_pts = (\n",
    "    q2[0][None, :] * 0.5 * new_tree.leaves.sizes[:, None, None] + new_tree.leaves.centers[:, None, :]\n",
    ")\n",
    "box_quad_wts = (\n",
    "    q2[1][None, :] * 0.25 * new_tree.leaves.sizes[:, None] ** 2\n",
    ")\n",
    "\n",
    "obs_test = np.array([0.05,0.05])\n",
    "sep = obs_test[None,:] - new_tree.leaves.centers\n",
    "obs_i = np.where(np.all(np.abs(sep) <= new_tree.leaves.sizes[:, None] / 2, axis=1))[0][0]\n",
    "\n",
    "obs_c = new_tree.leaves.centers[obs_i]\n",
    "obs_s = new_tree.leaves.sizes[obs_i]\n",
    "print(f'point contained in box {i}\\n  with center: {obs_c}\\n  and size: {obs_s}')\n",
    "obs_pts = q2[0] * 0.5 * obs_s + obs_c\n",
    "print(obs_c, obs_s)\n",
    "\n",
    "src_cs = new_tree.leaves.centers\n",
    "src_ss = new_tree.leaves.sizes\n",
    "transformed_obs_center = np.round(2 * (obs_c[None,:] - src_cs) / src_ss[:,None], decimals=1)\n",
    "transformed_obs_size = np.round(obs_s / src_ss, decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357512f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "G = (\n",
    "    fundamental_soln_matrix(obs_pts, box_high_pts.reshape((-1, 2)))[:, 0, :]\n",
    "    * box_quad_wts.ravel()[None,:]\n",
    ").reshape((q2[0].shape[0], src_cs.shape[0], q2[0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514d1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "src_terms = np.sum(G * new_tree.leaves.fhigh[None,:], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nearfield = 0\n",
    "add = 0\n",
    "for j in range(src_cs.shape[0]):\n",
    "    nearfield_info = boxes.get((transformed_obs_size[j], *transformed_obs_center[j]), None)\n",
    "    if nearfield_info is not None:\n",
    "        F = new_tree.leaves.fhigh[j]\n",
    "        integral_type, flipx, flipy, rotxy = nearfield_info\n",
    "        I = nearfield_box(nearfield_integrals[integral_type], F, flipx, flipy, rotxy)\n",
    "        basis_I = basis_integrals.ravel().dot(F.ravel())\n",
    "        scaled_I = scale_integral(I, basis_I, src_ss[j])\n",
    "\n",
    "        src_terms[:, j] = scaled_I.ravel()\n",
    "        nearfield += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ab781",
   "metadata": {},
   "outputs": [],
   "source": [
    "add, correct_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea65284",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = np.sum(src_terms, axis=1) + add\n",
    "\n",
    "print(f'there were {nearfield} nearfield cells')\n",
    "\n",
    "correct_cell = ethridge_soln_fnc(obs_pts[:,0], obs_pts[:,1])\n",
    "correct_pt = ethridge_soln_fnc(obs_test[0], obs_test[1])\n",
    "\n",
    "obs_test_transformed = (obs_test - obs_c) / (obs_s * 0.5)\n",
    "result_pt = barycentric_tensor_product(obs_test_transformed[:1], obs_test_transformed[1:], interp2[0], interp2[1], np.array([result]))[0,0]\n",
    "result_naive = naive_eval(new_tree, np.array([obs_test]))[0]\n",
    "print(correct_pt, result_pt)\n",
    "print(f'precompute interpolate at {obs_test} error is: {correct_pt - result_pt:.3e}')\n",
    "print(f'naive eval at {obs_test} error is: {correct_pt - result_naive:.3e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f583c01",
   "metadata": {},
   "source": [
    "## Check that tree integrates a simple function well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894eae6",
   "metadata": {},
   "source": [
    "#### Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a59a28b",
   "metadata": {},
   "source": [
    "There are two sources of error here:\n",
    "1. The integration error for the values of the integrals at the interpolation points.\n",
    "2. The interpolation error for the values of the integrals away from the interpolation points.\n",
    "\n",
    "Based on the previous demonstration, the first type of error is almost zero. The red points in the error figure above show the location of the interpolation points. You can see that the error oscillates around these points crossing zero at the points themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83915622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_test_transformed = (obs_test - obs_c) / (obs_s * 0.5)\n",
    "\n",
    "# Sprecompute = barycentric_tensor_product(obs_test_transformed[:1], obs_test_transformed[1:], interp2[0], interp2[1], np.array([result]))[0,0]\n",
    "\n",
    "# correct = ethridge_soln_fnc(obs_test[0], obs_test[1])\n",
    "\n",
    "# Snaive = naive_eval(balanced_tree, np.array([obs_test]))[0]\n",
    "\n",
    "# Sprecompute, correct, np.linalg.norm(Sprecompute - correct) / np.linalg.norm(correct)\n",
    "\n",
    "# Snaive, correct, np.linalg.norm(Snaive - correct) / np.linalg.norm(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250be54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box_high_pts = (\n",
    "#     q2[0][None, :] * 0.5 * new_tree.leaves.sizes[:, None, None] + new_tree.leaves.centers[:, None, :]\n",
    "# )\n",
    "# box_quad_wts = (\n",
    "#     q2[1][None, :] * 0.25 * new_tree.leaves.sizes[:, None] ** 2\n",
    "# )\n",
    "\n",
    "# obs_test = np.array([0.01,0.01])\n",
    "# for i in range(new_tree.leaves.centers.shape[0]):\n",
    "#     c = new_tree.leaves.centers[i]\n",
    "#     s = new_tree.leaves.sizes[i]\n",
    "#     sep = obs_test - c\n",
    "#     if np.all(np.abs(sep) <= s / 2):\n",
    "#         print(f'point contained in box {i}\\n  with center: {c}\\n  and size: {s}')\n",
    "#         obs_i = i\n",
    "\n",
    "# result = np.zeros((new_tree.leaves.fhigh.shape[1]))\n",
    "# obs_c = new_tree.leaves.centers[obs_i]\n",
    "# obs_s = new_tree.leaves.sizes[obs_i]\n",
    "# obs_pts = q2[0] * 0.5 * obs_s + obs_c\n",
    "# print(obs_c, obs_s)\n",
    "\n",
    "# nearfield = 0\n",
    "# for j in range(new_tree.leaves.centers.shape[0]):\n",
    "#     if j % 10000 == 0:\n",
    "#         print(f'starting cell {j}')\n",
    "#     src_c = new_tree.leaves.centers[j]\n",
    "#     src_s = new_tree.leaves.sizes[j]\n",
    "#     F = new_tree.leaves.fhigh[j]\n",
    "#     transformed_obs_center = np.round(2 * (obs_c - src_c) / src_s, decimals=1)\n",
    "#     transformed_obs_size = np.round(obs_s / src_s, decimals=1)\n",
    "\n",
    "#     nearfield_info = boxes.get((transformed_obs_size, *transformed_obs_center), None)\n",
    "\n",
    "#     if nearfield_info is not None:\n",
    "#         integral_type, flipx, flipy, rotxy = nearfield_info\n",
    "#         I = nearfield_box(nearfield_integrals[integral_type], F, flipx, flipy, rotxy)\n",
    "#         basis_I = basis_integrals.ravel().dot(F.ravel())\n",
    "#         scaled_I = scale_integral(I, basis_I, src_s)\n",
    "\n",
    "#         result += scaled_I.ravel()\n",
    "#         nearfield += 1\n",
    "#     else:\n",
    "#         sep = obs_c - src_c\n",
    "#         assert(not np.all(np.abs(sep) <= 0.5 * (obs_s + src_s)))\n",
    "#         G = (\n",
    "#             fundamental_soln_matrix(obs_pts, box_high_pts[j])[:, 0, :]\n",
    "#             * box_quad_wts[j].ravel()\n",
    "#         )\n",
    "#         result += G.dot(F)\n",
    "\n",
    "# print(f'there were {nearfield} nearfield cells')\n",
    "\n",
    "# correct_cell = ethridge_soln_fnc(obs_pts[:,0], obs_pts[:,1])\n",
    "# correct_pt = ethridge_soln_fnc(obs_test[0], obs_test[1])\n",
    "\n",
    "# obs_test_transformed = (obs_test - obs_c) / (obs_s * 0.5)\n",
    "# result_pt = barycentric_tensor_product(obs_test_transformed[:1], obs_test_transformed[1:], interp2[0], interp2[1], np.array([result]))[0,0]\n",
    "\n",
    "# result_naive_pt = naive_eval(new_tree, obs_test[None,:])[0]\n",
    "# print('cell errors: ', correct_cell - result)\n",
    "# print(f'precompute interpolate at {obs_test} error is: {correct_pt - result_pt:.3e}')\n",
    "# print(f'naive compute at {obs_test} error is {correct_pt - result_naive_pt:.3e}')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
